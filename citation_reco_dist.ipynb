{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "#from torch_geometric.loader import DataLoader \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_geometric.nn import GCNConv\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from torch.nn import Module, Linear\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Module, Linear\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Module, Linear\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import time\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "import gc\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import time\n",
    "import pickle\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/scai/msr/aiy227513/scratch/research/superSetAnalysis.csv')\n",
    "node_ids =[]\n",
    "node_features = []\n",
    "req_A=['citationVelocity', 'influentialCitationCount', 'isOpenAccess',\n",
    "       'isPublisherLicence', 'numCitebBy', 'numCiting','year']\n",
    "for index, row in df.iterrows():\n",
    "    paperId = row['paperId']\n",
    "    node_ids.append(paperId)\n",
    "    f=[]\n",
    "    for attribute in req_A:\n",
    "            if attribute==\"isOpenAccess\":\n",
    "             if row[attribute]==True:attribute_value=1\n",
    "             else:attribute_value=0\n",
    "            elif attribute==\"isPublisherLicence\":\n",
    "              if row[attribute]==True:attribute_value=1\n",
    "              else:attribute_value=0\n",
    "            else:\n",
    "               attribute_value = row[attribute]\n",
    "            f.append(attribute_value)\n",
    "    node_features.append(np.array(f).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('/home/scai/msr/aiy227513/scratch/research/data/superSetAnalysis.csv').sample(frac=1)\n",
    "node_ids_test =[]\n",
    "node_features_test = []\n",
    "sentence_test=[]\n",
    "for index, row in df_test.iterrows():\n",
    "    paperId = row['paperId']\n",
    "    if paperId in node_ids:continue\n",
    "    node_ids_test.append(paperId)\n",
    "    f=[]\n",
    "    sentence_test.append(row['abstract'])\n",
    "    for attribute in req_A:\n",
    "            if attribute==\"isOpenAccess\":\n",
    "             if row[attribute]==True:attribute_value=1\n",
    "             else:attribute_value=0\n",
    "            elif attribute==\"isPublisherLicence\":\n",
    "              if row[attribute]==True:attribute_value=1\n",
    "              else:attribute_value=0\n",
    "            else:\n",
    "               attribute_value = row[attribute]\n",
    "            f.append(attribute_value)\n",
    "    node_features_test.append(np.array(f).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/pbs.3721100.pbshpc/ipykernel_191187/533348573.py:4: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  node_features = torch.tensor(node_features, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/scai/msr/aiy227513/scratch/research/data/bert_encode.pkl\", \"rb\") as file:\n",
    "    embedding = pickle.load(file)\n",
    "    file.close()\n",
    "node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "embedding=torch.tensor(embedding, dtype=torch.float)\n",
    "feature=torch.cat([node_features,embedding], dim=1).float()\n",
    "feature =F.normalize(feature,p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert Embedding test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "class USE(nn.Module):\n",
    "    def __init__(self, model_name='bert-base-multilingual-cased'):\n",
    "        super(USE, self).__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    def forward(self, sentences):\n",
    "        inputs = self.tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "        \n",
    "        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        sentence_embeddings = torch.mean(outputs.last_hidden_state, dim=1)\n",
    "        \n",
    "        return sentence_embeddings\n",
    "\n",
    "\n",
    "# Example usage\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Check if CUDA is available\n",
    "model = USE().to(device)  # Move the model to the device\n",
    "batch_size = 1\n",
    "num_sentences = len(sentence_test)\n",
    "num_batches = (num_sentences + batch_size - 1) // batch_size  # Calculate the number of batches\n",
    "\n",
    "embeddings_test = []\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, num_sentences)\n",
    "        batch_sentences = sentence_test[start_idx:end_idx]\n",
    "        batch_sentences = [value for value in batch_sentences if not (isinstance(value, float) and math.isnan(value))]\n",
    "        if len(batch_sentences)==0:\n",
    "            batch_sentences.append('Dummy')\n",
    "        #print(batch_sentences)\n",
    "        # Tokenize the batch of sentences\n",
    "        inputs = model.tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        input_ids = inputs[\"input_ids\"].to(device)\n",
    "        attention_mask = inputs[\"attention_mask\"].to(device)\n",
    "\n",
    "        # Pass the inputs through the model\n",
    "        outputs = model.model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        batch_embeddings = torch.mean(outputs.last_hidden_state, dim=1)\n",
    "        \n",
    "        embeddings_test.append(batch_embeddings)\n",
    "\n",
    "# Concatenate the batch embeddings into a single tensor\n",
    "embeddings_test = torch.cat(embeddings_test, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([159156, 768])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159156"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(node_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159156"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/pbs.3721100.pbshpc/ipykernel_191187/4229892703.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  embeddings_test=torch.tensor(embeddings_test, dtype=torch.float).to(device)\n"
     ]
    }
   ],
   "source": [
    "node_features_test = torch.tensor(node_features_test, dtype=torch.float).to(device)\n",
    "embeddings_test=torch.tensor(embeddings_test, dtype=torch.float).to(device)\n",
    "feature_test=torch.cat([node_features_test,embeddings_test], dim=1).to(device)\n",
    "feature_test =F.normalize(feature_test,p=2, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkPredictionDataset(Dataset):\n",
    "    def __init__(self, nodes, node_attributes, edges):\n",
    "        self.nodes = nodes\n",
    "        self.node_attributes = node_attributes\n",
    "        self.edges = edges\n",
    "        #self.edge_index=edge_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.edges)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        src, dst,y = self.edges[index]\n",
    "        # src_node = self.node_attributes[src]\n",
    "        # dst_node = self.node_attributes[dst]\n",
    "        #print(src, dst,self.node_attributes,self.y[index])\n",
    "        return src, dst,self.node_attributes,y\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels=feature.shape[1], hidden_channels=512, out_channels=128, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphSAGE(in_channels,out_channels,num_layers)\n",
    "        #self.conv2 = GraphSAGE(hidden_channels, out_channels,num_layers)\n",
    "        self.fc1 = Linear(out_channels*2,128)\n",
    "        #self.fc2=Linear(256,128)\n",
    "        self.fc3=Linear(128,64)\n",
    "        self.fc4=Linear(64,16)\n",
    "        self.fc5=Linear(16,1)\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        #x = self.conv2(x, edge_index).relu()\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z,src,dst):\n",
    "        #return (z[0][src] * z[0][dst]).sum(dim=-1)\n",
    "        x=torch.cat([z[0][src],z[0][dst]], dim=-1)\n",
    "        x=F.leaky_relu(self.fc1(x))\n",
    "        #x=self.fc2(x).relu()\n",
    "        x=F.leaky_relu(self.fc3(x))\n",
    "        x=F.leaky_relu(self.fc4(x))\n",
    "        x=self.fc5(x)\n",
    "        return x\n",
    "#edge_index = torch.tensor([train_src,train_dest], dtype=torch.long).to(device)        \n",
    "model = GCN()\n",
    "#if torch.cuda.device_count() > 1:model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load('/home/scai/msr/aiy227513/scratch/research/model/model_bert.pth', map_location=device),\n",
    "                             strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  3.0072e-04,\n",
       "          1.1951e-04, -1.3999e-05],\n",
       "        [ 0.0000e+00,  1.9977e-03,  0.0000e+00,  ...,  4.9167e-04,\n",
       "          2.8023e-04, -4.6003e-05],\n",
       "        [ 0.0000e+00,  4.9641e-04,  0.0000e+00,  ...,  4.3379e-04,\n",
       "          1.0266e-04, -4.0684e-05],\n",
       "        ...,\n",
       "        [ 0.0000e+00,  2.4882e-03,  0.0000e+00,  ...,  3.6538e-04,\n",
       "          6.5855e-05, -4.2943e-05],\n",
       "        [ 0.0000e+00,  1.2758e-02,  0.0000e+00,  ...,  1.4996e-04,\n",
       "          1.3675e-04, -9.9754e-05],\n",
       "        [ 0.0000e+00,  1.9912e-03,  0.0000e+00,  ...,  3.1863e-04,\n",
       "          1.4046e-04, -4.0378e-05]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'edges' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m SAMPLE_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#y = torch.tensor(test_label, dtype=torch.float)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#edge_index = torch.tensor([test_src,test_dest], dtype=torch.long).to(device)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     test_dataset \u001b[38;5;241m=\u001b[39m LinkPredictionDataset(node_ids,feature,edges)\n\u001b[1;32m      7\u001b[0m     test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      8\u001b[0m     recommendations \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'edges' is not defined"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 1000\n",
    "\n",
    "with torch.no_grad():\n",
    "    #y = torch.tensor(test_label, dtype=torch.float)\n",
    "    #edge_index = torch.tensor([test_src,test_dest], dtype=torch.long).to(device)\n",
    "    test_dataset = LinkPredictionDataset(node_ids,feature,edges)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    recommendations = {}\n",
    "    for i in feature_test:\n",
    "        #src_nodes = np.random.randint(0, len(feature), size=SAMPLE_SIZE)\n",
    "        src_nodes = torch.from_numpy(i).to(device)\n",
    "        x=random.randint(len(feature), size=(SAMPLE_SIZE))\n",
    "        #l = np.random.randint(0, len(feature), size=SAMPLE_SIZE)\n",
    "        for j in x:\n",
    "                dst_node = torch.from_numpy(feature[j]).to(device)\n",
    "        #z = model.encode(node_attributes,edge_index)\n",
    "                z=torch.cat([src_nodes,dst_node], dim=1).to(device)\n",
    "                predictions=torch.sigmoid(model.decode(z)).view(-1)\n",
    "        recommendations[dst_node] = {'src_nodes': src_nodes, 'confidence': predictions}\n",
    "torch.save(recommendations, 'research/citation_recommendation/random_recommendations_ankit.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
