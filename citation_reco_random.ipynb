{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "#from torch_geometric.loader import DataLoader \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_geometric.nn import GCNConv\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from torch.nn import Module, Linear\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Module, Linear\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Module, Linear\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import time\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8231/3591135083.py:77: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
      "  node_features = torch.tensor(node_features, dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "#from torch_geometric.loader import DataLoader \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch_geometric.nn import GCNConv\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from torch.nn import Module, Linear\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Module, Linear\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch.nn import Module, Linear\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import math\n",
    "import pickle\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import time\n",
    "from torch_geometric.nn import GraphSAGE\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "df = pd.read_csv('/home/scai/msr/aiy227513/scratch/research/superSetAnalysis.csv')\n",
    "node_ids =[]\n",
    "node_features = []\n",
    "req_A=['citationVelocity', 'influentialCitationCount', 'isOpenAccess',\n",
    "       'isPublisherLicence', 'numCitebBy', 'numCiting','year']\n",
    "for index, row in df.iterrows():\n",
    "    paperId = row['paperId']\n",
    "    node_ids.append(paperId)\n",
    "    f=[]\n",
    "    for attribute in req_A:\n",
    "            if attribute==\"isOpenAccess\":\n",
    "             if row[attribute]==True:attribute_value=1\n",
    "             else:attribute_value=0\n",
    "            elif attribute==\"isPublisherLicence\":\n",
    "              if row[attribute]==True:attribute_value=1\n",
    "              else:attribute_value=0\n",
    "            else:\n",
    "               attribute_value = row[attribute]\n",
    "            f.append(attribute_value)\n",
    "    node_features.append(np.array(f).astype(np.float32))\n",
    "with open(\"/home/scai/msr/aiy227513/scratch/research/edges_same_ratio.pickle\", \"rb\") as file:\n",
    "    edges = pickle.load(file)\n",
    "    file.close()\n",
    "count=len(edges)\n",
    "train_size=math.floor((len(edges)*0.8))\n",
    "train_src=[]\n",
    "train_dest=[]\n",
    "train_label=[]\n",
    "for i in range(train_size):\n",
    " if edges[i][2]==1:\n",
    "    train_src.append(edges[i][0])\n",
    "    train_dest.append(edges[i][1])\n",
    "train_size=math.floor((len(edges)*0.8))\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "with open(\"/home/scai/msr/aiy227513/scratch/research/data/bert_encode.pkl\", \"rb\") as file:\n",
    "    embedding = pickle.load(file)\n",
    "    file.close()\n",
    "node_features = torch.tensor(node_features, dtype=torch.float)\n",
    "embedding=torch.tensor(embedding, dtype=torch.float)\n",
    "feature=torch.cat([node_features,embedding], dim=1).float()\n",
    "feature =F.normalize(feature,p=2, dim=-1)\n",
    "class LinkPredictionDataset(Dataset):\n",
    "    def __init__(self, nodes, node_attributes, edges):\n",
    "        self.nodes = nodes\n",
    "        self.node_attributes = node_attributes\n",
    "        self.edges = edges\n",
    "        #self.edge_index=edge_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.edges)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        src, dst,y = self.edges[index]\n",
    "        # src_node = self.node_attributes[src]\n",
    "        # dst_node = self.node_attributes[dst]\n",
    "        #print(src, dst,self.node_attributes,self.y[index])\n",
    "        return src, dst,self.node_attributes,y\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_channels=feature.shape[1], hidden_channels=512, out_channels=128, num_layers=4):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphSAGE(in_channels,out_channels,num_layers)\n",
    "        #self.conv2 = GraphSAGE(hidden_channels, out_channels,num_layers)\n",
    "        self.fc1 = Linear(out_channels*2,128)\n",
    "        #self.fc2=Linear(256,128)\n",
    "        self.fc3=Linear(128,64)\n",
    "        self.fc4=Linear(64,16)\n",
    "        self.fc5=Linear(16,1)\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        #x = self.conv2(x, edge_index).relu()\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def decode(self, z,src,dst):\n",
    "        #return (z[0][src] * z[0][dst]).sum(dim=-1)\n",
    "        x=torch.cat([z[0][src],z[0][dst]], dim=-1)\n",
    "        x=F.leaky_relu(self.fc1(x))\n",
    "        #x=self.fc2(x).relu()\n",
    "        x=F.leaky_relu(self.fc3(x))\n",
    "        x=F.leaky_relu(self.fc4(x))\n",
    "        x=self.fc5(x)\n",
    "        return x\n",
    "edge_index = torch.tensor([train_src,train_dest], dtype=torch.long).to(device)        \n",
    "model = GCN()\n",
    "#if torch.cuda.device_count() > 1:model = nn.DataParallel(model)\n",
    "model.load_state_dict(torch.load('/home/scai/msr/aiy227513/scratch/research/model/model_bert.pth', map_location=device),\n",
    "                             strict=False)\n",
    "g_truth=[]\n",
    "prediction=[]\n",
    "count=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = torch.load('random_recommendations_pratik2.pt', map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average recall score:  0.027507851734196336\n",
      "Average precision score:  0.00011965401249399328\n"
     ]
    }
   ],
   "source": [
    "recalls = []\n",
    "precisions = []\n",
    "for k in recommendations:\n",
    "    src_nodes = recommendations[k]['src_nodes']\n",
    "    scores = recommendations[k]['confidence']\n",
    "    \n",
    "    src_nodes = src_nodes.cpu().detach().numpy()\n",
    "    scores = scores.cpu().detach().numpy()\n",
    "    \n",
    "    tp = 0\n",
    "    total = 0\n",
    "    \n",
    "    for edge in edges:\n",
    "        if edge[2]==1 and edge[1]==k:\n",
    "            total += 1\n",
    "            if edge[0] in src_nodes:\n",
    "                tp += 1\n",
    "    \n",
    "    \n",
    "    rec = 0\n",
    "    pre = tp/len(src_nodes)\n",
    "    precisions.append(pre)\n",
    "    if total > 0:\n",
    "        rec = tp/total\n",
    "    recalls.append(rec)\n",
    "    \n",
    "print('Average recall score: ', np.mean(recalls))\n",
    "print('Average precision score: ', np.mean(precisions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([28240]) tensor([20722])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    #y = torch.tensor(test_label, dtype=torch.float)\n",
    "    #edge_index = torch.tensor([test_src,test_dest], dtype=torch.long).to(device)\n",
    "    test_dataset = LinkPredictionDataset(node_ids,feature,edges[train_size:])\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    batch = next(iter(test_dataloader))\n",
    "    print(batch[0], batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "src_nodes = np.random.randint(0, len(feature), size=50)\n",
    "src_nodes = torch.from_numpy(src_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "        5, 5], dtype=torch.int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(SAMPLE_SIZE, device=device, dtype=torch.int32) * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m         node_attributes\u001b[38;5;241m=\u001b[39mbatch[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#         y = batch[3].to(device)\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m         z \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(node_attributes,edge_index)\n\u001b[1;32m     23\u001b[0m         predictions\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mround(torch\u001b[38;5;241m.\u001b[39msigmoid(model\u001b[38;5;241m.\u001b[39mdecode(z,src_nodes,dst_nodes)))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m         recommendations[dst_node] \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msrc_nodes\u001b[39m\u001b[38;5;124m'\u001b[39m: src_nodes, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m'\u001b[39m: predictions}\n",
      "Cell \u001b[0;32mIn[10], line 108\u001b[0m, in \u001b[0;36mGCN.encode\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index):\n\u001b[0;32m--> 108\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x, edge_index)\u001b[38;5;241m.\u001b[39mrelu()\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m#x = self.conv2(x, edge_index).relu()\u001b[39;00m\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;66;03m#print(x.shape)\u001b[39;00m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.conda/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/gnn/lib/python3.11/site-packages/torch_geometric/nn/models/basic_gnn.py:226\u001b[0m, in \u001b[0;36mBasicGNN.forward\u001b[0;34m(self, x, edge_index, edge_weight, edge_attr, num_sampled_nodes_per_hop, num_sampled_edges_per_hop)\u001b[0m\n\u001b[1;32m    224\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs[i](x, edge_index, edge_attr\u001b[38;5;241m=\u001b[39medge_attr)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 226\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvs[i](x, edge_index)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjk_mode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/gnn/lib/python3.11/site-packages/torch_geometric/nn/conv/sage_conv.py:131\u001b[0m, in \u001b[0;36mSAGEConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    128\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mrelu(), x[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    130\u001b[0m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpropagate(edge_index, x\u001b[38;5;241m=\u001b[39mx, size\u001b[38;5;241m=\u001b[39msize)\n\u001b[1;32m    132\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin_l(out)\n\u001b[1;32m    134\u001b[0m x_r \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/gnn/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:484\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    482\u001b[0m         aggr_kwargs \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m res\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate(out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39maggr_kwargs)\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_forward_hooks\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m    487\u001b[0m     res \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, (aggr_kwargs, ), out)\n",
      "File \u001b[0;32m~/.conda/envs/gnn/lib/python3.11/site-packages/torch_geometric/nn/conv/message_passing.py:608\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21maggregate\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: Tensor, index: Tensor,\n\u001b[1;32m    596\u001b[0m               ptr: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m               dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    598\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m    :math:`\\bigoplus_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggr_module(inputs, index, ptr\u001b[38;5;241m=\u001b[39mptr, dim_size\u001b[38;5;241m=\u001b[39mdim_size,\n\u001b[1;32m    609\u001b[0m                             dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_dim)\n",
      "File \u001b[0;32m~/.conda/envs/gnn/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:109\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dim_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(index\u001b[38;5;241m.\u001b[39mmax()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(x, index, ptr, dim_size, dim, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/gnn/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/gnn/lib/python3.11/site-packages/torch_geometric/nn/aggr/basic.py:34\u001b[0m, in \u001b[0;36mMeanAggregation.forward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor, index: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     32\u001b[0m             ptr: Optional[Tensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, dim_size: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     33\u001b[0m             dim: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduce(x, index, ptr, dim_size, dim, reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/gnn/lib/python3.11/site-packages/torch_geometric/nn/aggr/base.py:155\u001b[0m, in \u001b[0;36mAggregation.reduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m segment(x, ptr, reduce\u001b[38;5;241m=\u001b[39mreduce)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m scatter(x, index, dim, dim_size, reduce)\n",
      "File \u001b[0;32m~/.conda/envs/gnn/lib/python3.11/site-packages/torch_geometric/utils/scatter.py:82\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     79\u001b[0m     count \u001b[38;5;241m=\u001b[39m count\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     81\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 82\u001b[0m     out \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(size)\u001b[38;5;241m.\u001b[39mscatter_add_(dim, index, src)\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out \u001b[38;5;241m/\u001b[39m broadcast(count, out, dim)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# For \"min\" and \"max\" reduction, we prefer `scatter_reduce_` on CPU or\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# in case the input does not require gradients:\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 50\n",
    "\n",
    "with torch.no_grad():\n",
    "    #y = torch.tensor(test_label, dtype=torch.float)\n",
    "    #edge_index = torch.tensor([test_src,test_dest], dtype=torch.long).to(device)\n",
    "    test_dataset = LinkPredictionDataset(node_ids,feature,edges[train_size:])\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "    recommendations = {}\n",
    "    for batch_idx, batch in enumerate(test_dataloader):\n",
    "        #src_nodes, dst_nodes,node_attributes,y = batch\n",
    "        \n",
    "#         src_nodes=batch[0].to(device)\n",
    "        np.random.seed(batch_idx)\n",
    "        src_nodes = np.random.randint(0, len(feature), size=SAMPLE_SIZE)\n",
    "        src_nodes = torch.from_numpy(src_nodes).to(device)\n",
    "#         print(dst_nodes.item())\n",
    "        dst_node = batch[1].item()\n",
    "        dst_nodes = torch.ones(SAMPLE_SIZE, device=device, dtype=torch.int32) * dst_node\n",
    "#         dst_nodes=batch[1].to(device)\n",
    "        node_attributes=batch[2].to(device)\n",
    "#         y = batch[3].to(device)\n",
    "        z = model.encode(node_attributes,edge_index)\n",
    "        predictions=torch.round(torch.sigmoid(model.decode(z,src_nodes,dst_nodes))).view(-1)\n",
    "        recommendations[dst_node] = {'src_nodes': src_nodes, 'confidence': predictions}\n",
    "        #print(predictions)\n",
    "#         if predictions==y.float():count+=1\n",
    "#         g_truth.append(y.item())\n",
    "#         prediction.append(predictions.item())\n",
    "        #print('Predictions:', predictions)\n",
    "# print(\"Accuracy:\",(count/(batch_idx+1))*100,\"%\")\n",
    "# cm = confusion_matrix(np.array(g_truth),np.array(prediction))\n",
    "\n",
    "# #print(cm)\n",
    "# labels = ['Class 0', 'Class 1']\n",
    "# cmap = plt.cm.Blues\n",
    "\n",
    "# # Create figure and axes\n",
    "# fig, ax = plt.subplots()\n",
    "# im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "\n",
    "# # Show all ticks and label them with the respective list entries\n",
    "# ax.set_xticks(range(len(labels)))\n",
    "# ax.set_yticks(range(len(labels)))\n",
    "# ax.set_xticklabels(labels)\n",
    "# ax.set_yticklabels(labels)\n",
    "\n",
    "# # Add text inside each cell\n",
    "# for i in range(len(labels)):\n",
    "#     for j in range(len(labels)):\n",
    "#         ax.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\", color=\"white\" if cm[i, j] > cm.max() / 2 else \"black\")\n",
    "\n",
    "# # Set plot labels and title\n",
    "# plt.xlabel(\"Predicted labels\")\n",
    "# plt.ylabel(\"True labels\")\n",
    "# plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# # Add a color bar\n",
    "# plt.colorbar(im)\n",
    "\n",
    "# # Show the plot\n",
    "# #plt.show()\n",
    "# plt.savefig('scratch/research/plots/adadelta_nlp_sage_cnf_matrix.jpeg')\n",
    "# # %%\n",
    "# f1 = f1_score(np.array(g_truth),np.array(prediction))\n",
    "\n",
    "# print(\"F1 score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(recommendations, 'random_recommendations_pratik.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations = {1: {'src_nodes':[0], 'confidence':[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for \n",
    "for edge in edges:\n",
    "    if edge[2]==1 and edge[1]=="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('/home/scai/msr/aiy227513/scratch/research/superSetAnalysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_ids =[]\n",
    "# node_features = []\n",
    "# req_A=['citationVelocity', 'influentialCitationCount', 'isOpenAccess',\n",
    "#        'isPublisherLicence', 'numCitebBy', 'numCiting','year']\n",
    "# for index, row in df.iterrows():\n",
    "#     paperId = row['paperId']\n",
    "#     node_ids.append(paperId)\n",
    "#     f=[]\n",
    "#     for attribute in req_A:\n",
    "#             if attribute==\"isOpenAccess\":\n",
    "#              if row[attribute]==True:attribute_value=1\n",
    "#              else:attribute_value=0\n",
    "#             elif attribute==\"isPublisherLicence\":\n",
    "#               if row[attribute]==True:attribute_value=1\n",
    "#               else:attribute_value=0\n",
    "#             else:\n",
    "#                attribute_value = row[attribute]\n",
    "#             f.append(attribute_value)\n",
    "#     node_features.append(np.array(f).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"/home/scai/msr/aiy227513/scratch/research/edges_same_ratio.pickle\", \"rb\") as file:\n",
    "#     edges = pickle.load(file)\n",
    "#     file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
